%?????????????????????????
% Nombre: capitulo3.tex  
% 
% Texto del capitulo 3
%---------------------------------------------------

\chapter{Teoría}
\label{teoria}

En este capítulo asentaremos los conceptos teóricos utilizados en el transcurso del anterior apartado. Comenzaremos con el concepto de \textbf{clasificación} y finalizaremos con el concepto de \textbf{concept drift}. 

\section{Clasificación}

\textit{Explicar el problema de clasificación, los clasificadores utilizados en los experimentos de la sección 2, y en qué consisten los diferentes modos de evaluación/validación en flujos de datos}.

El problema de la clasificación es uno de los problemas más ampliamente estudiado en ciencia de datos. Se basa en el entrenamiento y construcción de modelos predictivos en base a un conocimiento previo que viene dado en forma de datasets pre-etiquetados, una vez obtenido estos modelos, se deberá poder predecir la etiqueta o clase de una nueva muestra que se incluya al problema y de la cual no sabemos su clase de pertenencia.  En minería de flujo de datos el problema es similar, salvo por que los datos nos llegan en un flujo continuo, de manera que no podemos tener todo el dataset a priori para aprender y validar con las consiguientes dificultades que esto aporta al problema. 

Los clasificadores usados en los experimentos anteriores son dos, concretamente el \textbf{Hoeffding Tree} y el \textbf{Hoeffding Tree Adaptativo}.

\begin{itemize}
\item \textbf{Hoeffding Tree}: Es un algoritmo basado en árboles de decisión que trabaja de manera incremental de ahí su uso para trabajar con flujos de datos. Asume que la distribución de ejemplos no cambia en el tiempo y  se basa en el principio matemático de Hoeffding, que nos dice el número de ejemplos que son estadísticamente necesarios para partir una rama del árbol en pos de mejorar o no empeorar las medidas de bondad. Acorde a este principio, los arboles explotan la idea de que un conjunto pequeño de muestras puede ser usada para crear un buen árbol de decisión y de  ahí procede su potencia en determinados problemas como los de flujo de datos. Es un algoritmo bastante eficiente donde tanto el tiempo como la memoria para construir los modelos son lineales y no dependen del número de ejemplos en el stream. 

\item \textbf{Hoeffding Tree Adaptativo}: Este algoritmo es una versión del algoritmo anterior con idéntico funcionamiento pero que hace uso de ADWIN (Adaptative Window) para monitorizar los cambios de diferencia entre valores medios, con lo que detecta posibles descensos de accuracy en las ramas del árbol y las intercambia por mejores soluciones, acorde al accuracy, en la medida de lo posible por lo que a pesar de ser computacionalmente más complejo, los resultados serán en la mayoría de los casos mejores. 

\end{itemize}

Si dejamos de lado los clasificadores y nos centramos en los métodos de evaluación usados encontramos tres diferentes:

\begin{enumerate}
\item \textbf{Evaluación offline}: Este método de evaluación es el tradicional en el que se usa un conjunto de datos para construir el modelo (train) y posteriormente se evalúa con otro conjunto de datos diferente al utilizado para entrenar. Es el típico proceso de evaluación de clasificadores utilizado para problemas fuera del ámbito del flujo de datos. 
\item \textbf{Interleaved Test Then Train}: Este método es el más común en flujo de datos, se basa en utilizar cada nuevo dato del flujo para probar el modelo y posteriormente se añade este dato a la fase de entrenamiento. Este método concretamente se realiza de manera incremental es decir, cada nuevo dato que va llegando se va teniendo en cuenta desde el inicio hasta el fin, siendo esta la principal diferencia con el método prequential que ahora veremos. 
\item \textbf{Prequential}:  El método prequential en moa usa la misma filosofía de \textit{test then train} pero usa una ventana deslizante cuyo valor podemos fijar. Esta ventana deslizante nace de la filosofía de que los datos nuevos son los mas relevantes por lo que el modelo de train se va construyendo bajo el umbral de esta ventana deslizante olvidando los datos mas antiguos.
\end{enumerate}

\section{Concept Drift}

\textit{Explicar en qué consiste el problema de concept drift y qué técnicas conoce para resolverlo en clasificación.}

El \textbf{\textit{concept drift}}, o cambio de contexto es uno de los principales problemas a los que nos enfrentamos en la minería de flujo de datos y viene a significar que los datos que han llegado en el pasado difieren en mayor o menor medida en los datos que estamos trabajando en este mismo momento por lo que se entra en conflicto con asunciones pasadas sobre los datos y causará un descenso de las medidas de bondad que en algunos casos puede llegar a ser drástico. Detectar estos cambios de contexto apropiadamente y readaptar los modelos será por tanto un gran reto pero necesario en los problemas de minería de flujo de datos. Su importancia en estos problemas es tal que han propiciado una gran línea de investigación con trabajos muy recientes que tratan sobre soluciones en la materia \cite{cd1} \cite{cd2} \cite{cd3} \cite{cd4}.

Como hemos introducido anteriormente, el \textbf{\textit{concept drift}} se debe a cambios en los datos, pero estos no vendrán dados siempre de la misma manera sino que podrán presentarse de manera recurrente, gradual, incremental o brusco acorde a los ejemplos que podemos ver en la figura \ref{figcd}.
 
\begin{figure}[h]
	\centering
		\includegraphics[scale=0.4]{./Capitulo3/imagenes/figcd.png}
		\caption{Tipos de concept drift.}
	\label{figcd}
\end{figure}
 
El cambio de contexto podrá deberse a diversos motivos como pueden ser, la variación de características, la presencia de ruido, aparición de nuevas características o la influencia del entorno, siendo este uno de los motivos más delicados. Igualmente, sea cual sea el motivo del cambio de contexto, encontramos los siguientes métodos u algoritmos para para solventar el problema:

\begin{itemize}

\item  \textbf{Aprendizaje Online}: Estos algoritmos continuamente actualizan los parámetros de clasificación mientras el flujo de datos está activo. Hay que tener en cuenta que cada ejemplo solo debe ser procesado una vez, su rendimiento no debería ser distinto a los algoritmos offline y y los requisitos de tiempo y procesado deben ser limitados. Un algoritmo muy común dentro de esta categoría sería el CVFDT \cite{CVFDT}.

\item \textbf{Soluciones de ventana}: Son algoritmos que olvidan datos antiguos conforme llegan datos nuevos, asumiendo que estos últimos tienen más relevancia en el problema. Esta solución, hace que de cara a un cambio de contexto el algoritmo reaprenderá este cambio de contexto y aunque tendrá cierto descenso en sus medidas en algún momento temporal, se recuperará y volverá a ofrecer resultados similares a los ofrecidos antes del cambio de contexto. Las soluciones más afamadas son la ventana deslizante, ventana en función de hitos y la ponderación de datos en función de la antigüedad. 

\item \textbf{Ensembles}: Estos son algoritmos que entrenan diversos modelos de clasificadores elementales con ciertas variaciones de manera que la decisión final es una decisión colectiva entre todos ellos. Esta diversidad o variaciones para entrenar pueden deberse a las características, el modelo de clasificación o las instancias usadas para entrenar siendo estos conceptos muy relevantes en entornos cambiantes donde la diversidad puede venir marcada por los nuevos datos del stream, incluido el hipotético cambio de contexto. Los algoritmos más famosos dentro de este área serían los de Street \cite{street} y el de Wang \cite{wang}. 

\item  \textbf{Algoritmos de detección}: Estos algoritmos en lugar de buscar adaptabilidad buscan detectar cuando se producirá cambio de contexto para posteriormente paliar sus efectos. Para detectar un cambio de contexto se suele analizar la disminución de las medidas de bondad. En estos algoritmos encontramos el problema de cuando detectar el cambio de contexto, si esperamos mucho una vez iniciado el mismo estaremos ante un método que es robusto, pero que perderá accuracy al activar los procesos tarde. Por otro lado, hacen saltar la alarma rápidamente el algoritmo paliará los efectos cuando el cambio de contexto aún no haya perjudicado mucho el modelo, pero por contra se enfrenta al problema de un elevado número de falsos positivos. 
 
\end{itemize}
\pagebreak
\clearpage
%---------------------------------------------------